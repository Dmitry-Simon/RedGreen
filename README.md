# RedGreen - Capstone Project Phase A

## Overview

**RedGreen** is a capstone project that explores the use of machine learning to identify fruit ripeness, specifically focusing on watermelon. The project integrates both **visual and acoustic** analysis to assess watermelon quality, leveraging advanced **deep learning models**.

This repository currently contains only **the research phase** of the project. It includes:
- The **project documentation**
- **Reference materials** used in the research phase

## Research Objective

The goal of this research is to develop a **machine learning-based approach** to evaluate watermelon quality. The study integrates:
1. **Image-based analysis** â€“ Identifying ripeness using **YOLOv8** for real-time object detection.
2. **Sound-based analysis** â€“ Evaluating ripeness through **ECAPA-TDNN**, which analyzes tapping sounds.

By combining these methods, the system aims to provide **a more accurate and reliable** assessment of watermelon ripeness.

## Current Repository Contents

This repository currently consists of:
- **Project summary documents** (PDF and DOCX)
- **Reference research papers** on fruit ripeness detection
- **Phase A report** covering:
  - Literature review
  - Methodology
  - Challenges
  - Expected outcomes

## Project Status

ðŸš§ **This repository is in the research phase** ðŸš§  
No code or implementation has been added yet. Future phases will involve:
- Data collection and preprocessing
- Model development and testing
- Deployment and application development

## References

The research phase references multiple academic papers and machine learning models, including:
- **"Fruit Ripeness Identification Using YOLOv8 Model"** - Explores how deep learning can classify fruit ripeness based on visual indicators.
- **"Non-Destructive Ripeness Judgment of Watermelon Using ECAPA-TDNN"** - Demonstrates the use of sound frequency analysis for assessing ripeness.

For more details, please refer to the **Capstone Project Phase A** documents in this repository.
